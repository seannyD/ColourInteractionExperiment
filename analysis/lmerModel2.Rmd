---
title: "Colour experiment"
output: 
    pdf_document:
        toc: true
---


\newpage

# Introduction

This analysis looks at the sign variants used in a colour naming game between signers of different sign languages meeting after 1 week of interaction and after 3 weeks of interaction.  The data was collected by Kang Suk Byun (Kang-Suk.Byun@mpi.nl).

The analysis tries to predict the relative frequency of each variant within a colour category in week 3, based on measures from week 1.

## Data

-  colour: Code of the target colour
-  colourName: English name of the target colour
-  sign: label for the variant produced
-  freq_week_1_total: Total number of occurances of the variant in the first week, across all colour contexts.
-  freq_week_4_total: Total number of occurances of the variant in the final week, across all colour contexts.
-  freq_week_1: Number of occurances of the variant used during the given target colour context in week 1.
-  freq_week_4: Number of occurances of the variant used during the given target colour context in the final week.
-  prop_week_1: Same as freq_week_1, but as a proportion of all variants used in the given colour context.
-  prop_week_4: Same as freq_week_4, but as a proportion of all variants used in the given colour context.
-  origin:  The origin language of the sign.  For many, identifying an origin is not possible, so is labelled "None"
-  iconic: Old variable
-  check: The number of times this variable was used in a checking turn.
-  indexical:  Is the variant non-indexical, indexical or indexical of the body?
-  inventedBy:  The name of the first signer to use this variant in the experiment.
-  TryMarked:  The number of times this sign was used in try-marking.
-  Teach:  The number of times this sign was explicitly taught.
-  averageLength_week_1:  Average time to produce the variant in milliseconds
-  averageTrialLength_week_1:  Average time for completing the trial for the given target colour.
-  BodyAnchor:  Is the variant body-anchored (redundant with 'indexical')

\newpage

## Poisson regression

This study uses a mixed effects regression model with poisson distributions.  Most standard regression analyses assume that the values they are trying to model come from a normal distribution, like this:

```{r echo=F}
set.seed(237)
hist(rnorm(1000, mean = 8, sd = 2), main='', xlab='Frequency', ylab='Count')
```

However, the main variable for this study is the frequency of sign variants, with a strong skew and many zero values:

```{r echo=F}
variants = read.csv('../data/processedData/variants_summary.csv', stringsAsFactors = F)
hist(variants$freq_week_4, main='', xlab='Frequency', ylab='Count')
```

Instead of using a normal distribution as the basis for the statistical model or transforming the data (which is difficult anyway because of the large number of zero counts), we can use a poisson distribution.  This also has the advantage of only predicting whole, non-negative numbers, which makes sense for this data because a variant can't be used half a time or a negative number of times.

# Load libraries
```{r warning=F, message=F}

library(ggplot2)
library(lme4)
library(Rmisc)
library(dplyr)
library(sjPlot)
library(gridExtra)
```

```{r echo=F}

setwd("~/Documents/MPI/KangSukColours/ColourExperiment/analysis/")

getMEText = function(r,ef, wald=NULL, showWald=F){
  
  AIC = r[2,]$AIC
  loglikDiff = signif(diff(r$logLik),2)
  chi = round(r$Chisq[2],2)
  df = r$`Chi Df`[2]
  p = signif(r$`Pr(>Chisq)`[2],2)
  
  wald.text = ""
  
  if(!is.null(wald)){
    est = signif(wald[1],2)
    stder = signif(wald[2],2)
    t = signif(wald[3],2)
    wptext = ""
    wald.text =  paste("beta = ",est,",")
    if(showWald){
      if(!is.na(wald[4])){
      wptext = paste(", Wald p =",signif(wald[4],2))
      }
    wald.text = paste("beta = ",est,", std.err = ",stder, ", Wald t = ",t,wptext,';')
    }
  }
  
  begin = 'There was no significant'
  if(p <0.09){
    begin = "There was a marginal"
  }
  if(p < 0.05){
    begin = 'There was a significant'  
  }
  
  
  return(paste(begin,ef,"(",wald.text,"log likelihood difference =",
               loglikDiff,", df = ",df,", Chi Squared =", chi,", p = ",p,")."))
}

```

# Load data

```{r}
variants = read.csv('../data/processedData/variants_summary.csv', stringsAsFactors = F)
```

There is only 1 variant for `white'.  Therefore, we remove it from this statistical analysis.

```{r}
variants = variants[variants$colourName!='white',]
```

Some variants need to be removed:

```{r}
variants = variants[!variants$sign %in%
            c("SAME",
              "DIFFERENT",
              "DO NOT UNDERSTAND"),]
```


Transform some variables.

```{r}

# The range of values for 'Teach' is very small:
table(variants$Teach)
# So we'll turn it into a binary category: 
#  variants that were never taught and variants that were
variants$Teach = as.factor(variants$Teach >0)

# Similar for checking
variants$check.any = as.factor(variants$check>0)

# ... and T-1

variants$T_minus_1.any = as.factor(variants$T_minus_1>0)

# Transform total frequency
variants$freq_week_1_total.logcenter = 
  log(variants$freq_week_1_total + 1)
variants$freq_week_1_total.logcenter = scale(variants$freq_week_1_total.logcenter)

# cut TryMarking into two categories
variants$TryMarked.any = as.factor(variants$TryMarked>0)

# transform length
variants$averageLength_week_1.logcenter = log(variants$averageLength_week_1)
variants$averageLength_week_1.logcenter =
  scale(variants$averageLength_week_1.logcenter)

variants$indexical = as.factor(variants$indexical)

# Make inventedBy deviation coding 
#  (deviation from the grand mean)
variants$inventedBy = as.factor(variants$inventedBy)
contrasts(variants$inventedBy) = contr.sum(length(levels(variants$inventedBy)))


listofsigns = variants[,c("colourName","sign")]
write.csv(listofsigns,"../results/descriptive/ListOfVariants.csv", fileEncoding = 'utf-8')

```


# LMER models

Each model predicts the frequency of a variant in week 4, with a random intercept by colourName.  The random intercept allows some colours to have higher variant frequencies than others.  This is useful because we know that signs for some colours are converged on quickly, making their frequencies within those colours potentially higher.  In other words, the use of a particular variant to refer to a given colour is not entierly independent of the use of another variant to refer to the same colour.

Random slopes allow the strength of the effect of a factor to be different for each colour concept.  Only indexicality is theoretically relevant here: it is possible that an indexical strategy, particularly body-indexical signs, would be more effective for some colours than others.  For example, the body affords indexicality for black (hair) and red (tongue), but not green.  We can check whether this is true by comparing a baseline model to one with a random slope for indexicality.

```{r ranEfTest, cache=T}
# Optimiser adjustments
gcontrol = control=glmerControl(
  optimizer = 'bobyqa',
  optCtrl = list(maxfun = 1000000))

m0 = glmer(freq_week_4 ~ 
             1
           + (1 | colourName) , 
           data=variants, family=poisson,
           control=gcontrol)

m1 = glmer(freq_week_4 ~ 
             1
           + (1 + indexical || colourName) , 
           data=variants, family=poisson,
           control=gcontrol)
anova(m0,m1)
```

Indeed, a random slope for indexicality significantly improves the model.  It is difficult to think of a theoretical reason why different colours would be affected differently for other variables.  Given that random slopes make the model more complex, these are left out.

We begin with a null model and gradually add predictor variables, using model comparison to judge the significance of each variable.

```{r modelBits, cache=T}
# Null model
m0 = glmer(freq_week_4 ~ 
             1
           + (1 + indexical || colourName) , 
           data=variants, family=poisson,
           control=gcontrol)

# add indexicality
mIndx = glmer(freq_week_4 ~ 
                1 + 
                indexical + 
                (1 + indexical || colourName) , 
              data=variants, family=poisson,
              control=gcontrol)

# add whether the variant is explicitly taught
mTeach = glmer(freq_week_4 ~ 
                 1 +  
                 indexical + 
                 Teach +
                 (1 + indexical || colourName) , 
               data=variants, family=poisson,
               control=gcontrol)

mTry = glmer(freq_week_4 ~ 
               1 +  
               indexical + 
               Teach +
               TryMarked.any +
               (1 + indexical || colourName) , 
             data=variants, family=poisson,
             control=gcontrol)

mChk = glmer(freq_week_4 ~ 
               1 +  
               indexical + 
               Teach +
               TryMarked.any +
               check.any +
               (1 + indexical || colourName) , 
             data=variants, family=poisson,
             control=gcontrol)

mTm1 = glmer(freq_week_4 ~ 
               1 +  
               indexical + 
               Teach +
               TryMarked.any +
               check.any +
               T_minus_1.any +
               (1 + indexical || colourName) , 
             data=variants, family=poisson,
             control=gcontrol)

mFrq = glmer(freq_week_4 ~ 
               1 +  
               indexical + 
               Teach +
               TryMarked.any +
               check.any +
               T_minus_1.any +
               freq_week_1_total.logcenter +
               (1 + indexical || colourName) , 
             data=variants, family=poisson,
             control=gcontrol)

mLen = glmer(freq_week_4 ~ 
               1 +  
               indexical + 
               Teach +
               TryMarked.any +
               check.any +
               T_minus_1.any +
               freq_week_1_total.logcenter +
               averageLength_week_1.logcenter +
               (1 + indexical || colourName) , 
             data=variants, family=poisson,
             control=gcontrol)

mInv = glmer(freq_week_4 ~ 
               1 +  
               indexical + 
               Teach +
               TryMarked.any +
               check.any +
               T_minus_1.any +
               freq_week_1_total.logcenter +
               averageLength_week_1.logcenter +
               inventedBy +
               (1 + indexical || colourName) , 
             data=variants, family=poisson,
             control=gcontrol)

mTchXTry = glmer(freq_week_4 ~ 
                   1 +  
                   indexical + 
                   Teach +
                   TryMarked.any +
                   check.any +
                   T_minus_1.any +
                   freq_week_1_total.logcenter +
                   averageLength_week_1.logcenter +
                   inventedBy +
                   Teach : TryMarked.any +
                   (1 + indexical || colourName) , 
                 data=variants, family=poisson,
                 control=gcontrol)

# Interaction of teaching and checking causes severe 
#  convergence issues
# m10 = glmer(freq_week_4 ~ 
#              1 +  
#              indexical + 
#              Teach +
#              TryMarked.any +
#              check.any +
#              T_minus_1.any +
#              freq_week_1_total.logcenter +
#              averageLength_week_1.logcenter +
#              inventedBy +
#              Teach : TryMarked.any +
#              Teach : check.any +
#             (1 + indexical || colourName) , 
#            data=variants, family=poisson,,
#            control=gcontrol)

mTryXChk = glmer(freq_week_4 ~ 
                   1 +  
                   indexical + 
                   Teach +
                   TryMarked.any +
                   check.any +
                   T_minus_1.any +
                   freq_week_1_total.logcenter +
                   averageLength_week_1.logcenter +
                   inventedBy +
                   Teach : TryMarked.any +
                   TryMarked.any : check.any +
                   (1 + indexical || colourName) , 
                 data=variants, family=poisson,
                 control=gcontrol)

```

# Results

Model comparison test:
  
```{r}
anova(m0,mIndx,mTeach,mTry,mChk,mTm1,mFrq,mLen,mInv,mTchXTry,mTryXChk)
```

Choose a final model for the beta values.

```{r}
finalModel = mTchXTry
```

\newpage

Full summary:

```{r}
summary(finalModel)
```


Check the predictions:

```{r}
plot(variants$freq_week_4, exp(predict(finalModel)),
     xlab="Actual frequency",
     ylab="Model prediction")
abline(0,1)
```

```{r echo=F}
tx = table(
  exp(predict(finalModel))>=1,
  variants$freq_week_4>=1)
```

These are the variants used in the final week:

```{r}
variants[variants$freq_week_4>0,c("colourName","sign", 'freq_week_4')]
```

There were `r sum(variants$freq_week_4>0)` variants that had a frequency of greater than 0 in the final week.  

The model predicts `r tx[2,2]` of these correctly, missing `r tx[1,2]` variants (`r paste(variants[variants$freq_week_4>0 & exp(predict(finalModel))<1,]$sign,collapse=", ")`).  

The model predicts a further `r tx[2,1]` variants should have been observed in the final week but were not observed in reality:

```{r echo=F}
variants[variants$freq_week_4==0 & exp(predict(finalModel))>=1,c("colourName","sign")]
```



## Random slopes results

We can plot the random slopes below:

```{r}
dotplot(ranef(finalModel))
```

The effect of indexicality is stronger for red and brown, and weaker for pink.

Check whether the coefficients are radically different with a full random effects structure:

```{r checkFullModel, cache=T}
finalModelFull = update(finalModel, ~. + 
                          (0 + Teach + check.any +
                             T_minus_1.any + inventedBy || colourName))
cor.test(fixef(finalModel), fixef(finalModelFull))
```

The correlation is high, suggesting that the extra random slopes would not have a big effect on the results.

\newpage

# Summary

Here is a summary of the main results:

`r getMEText(anova(m0,mIndx), "main effect of indexicality",summary(finalModel)$coef['indexicalYes',])` (beta for body-indexical = 0.853). Indexical variants were more frequent in the final week.

`r getMEText(anova(mIndx,mTeach), "main effect of teaching",summary(finalModel)$coef['TeachTRUE',])`  Teaching increased the frequency of variants in the final week.

`r getMEText(anova(mTeach,mTry), "main effect of try marking",summary(finalModel)$coef['TryMarked.anyTRUE',])` Variants that were try marked more often were more frequent in the final week.

`r getMEText(anova(mTry,mChk), "main effect of checking",summary(finalModel)$coef['check.anyTRUE',])`  Variants used in a checking context were more frequent in the final week.


`r getMEText(anova(mChk,mTm1), "main effect of use in repair initiation (T-1)",summary(finalModel)$coef['T_minus_1.anyTRUE',])` 


`r getMEText(anova(mTm1,mFrq), "main effect of frequency in week 1",summary(finalModel)$coef['freq_week_1_total.logcenter',])`  More frequent forms in the first week were more likely to be more frequent in the final week.

`r getMEText(anova(mFrq,mLen), "main effect of sign length",summary(finalModel)$coef['averageLength_week_1.logcenter',])`  Shorter signs were more frequent in the final week.

`r getMEText(anova(mLen,mInv), "main effect of first user (inventedBy)")`  Signs invented by the signer from Nepal were less frequent in the final week.

`r getMEText(anova(mInv,mTchXTry), "interaction between try marking and teaching",summary(finalModel)$coef['TeachTRUE:TryMarked.anyTRUE',])` The effect of teaching was bigger when the variant was also often try marked (see graphs below). 


We also found some evidence that the effect of indexicality is more important for black and red, and less important for green and pink.

\newpage

# Graphs


## Teaching and Try marking

Plot the interaction between teaching and try marking.  Variants are more frequent in the final week if they were both taught and try marked.  However, the second plot shows that there are actually relatively few taught variants, suggesting that the results may not generalise well.


```{r}
sumStats2 = summarySE(variants, measurevar="freq_week_4",
                      groupvars=c("TryMarked.any","Teach"))
sumStats2$TryMarked.any = c("No","Yes")[as.numeric(sumStats2$TryMarked.any)]
dodge <- position_dodge(width=0.5) 

main.plot <- ggplot(sumStats2,
	aes(x = TryMarked.any, y = freq_week_4, colour=Teach)) +
  geom_point(position=dodge, size=4) + 
  geom_line(aes(group=Teach),position=dodge) +
  geom_errorbar(aes(ymax=freq_week_4+se, ymin=freq_week_4-se), width=0.25,position=dodge) +
  xlab("Try Marked") +
  ylab("Frequency in week 3") +
  coord_cartesian(ylim=c(0,6)) + 
  scale_color_discrete(breaks=c(TRUE,FALSE),
                       labels=c("Yes","No"),
                       name="Teach") +
  theme(text=element_text(size=18))
main.plot


ggplot(variants,
	aes(x = TryMarked.any, y = freq_week_4, colour=Teach)) + geom_jitter()
```

```{r echo=F}
pdf("../results/descriptive/graphs/Interaction_Teach_TryMark.pdf", height=5, width=6)
main.plot
dev.off()
```

Plot of the marginal effects of the predicted probabilities for each fixed effect:

```{r warning=F}
x = sjp.glmer(finalModel, 'eff', 
          vars=c("indexical",'check.any','averageLength_week_1.logcenter',
            'freq_week_1_total.logcenter'), 
          facet.grid = F,
          prnt.plot = F)

# Rescale frequency back to real values
freq.m = x$plot.list[[3]]$data$x
x$plot.list[[3]]$data$x = 
  exp(freq.m* 
  attr(variants$freq_week_1_total.logcenter, 'scaled:scale') + 
  attr(variants$freq_week_1_total.logcenter, 'scaled:center') -1)

# Rescale length back to real values
len.m = x$plot.list[[4]]$data$x
x$plot.list[[4]]$data$x = 
  exp(len.m* 
  attr(variants$averageLength_week_1.logcenter, 'scaled:scale') + 
  attr(variants$averageLength_week_1.logcenter, 'scaled:center') -1)

x$plot.list[[1]]$labels$title = "Indexicality"
x$plot.list[[1]]$scales$scales[[1]]$labels = c("No","Yes","Body")
x$plot.list[[2]]$labels$title = "Checking"
x$plot.list[[2]]$scales$scales[[1]]$labels = c("No","Yes")
x$plot.list[[3]]$labels$title = "Frequency (W1)"
x$plot.list[[4]]$labels$title = "Length (ms)"
for(i in 1:4){
  x$plot.list[[i]]$coordinates$limits$y = c(0,0.2)
  if(i>1){
    x$plot.list[[i]]$theme = 
      list(
        panel.grid.minor.x = element_blank(),
        axis.text.y = element_blank(),
        axis.line.y=element_blank())
  } else{
    x$plot.list[[i]]$theme = list(panel.grid.minor.x = element_blank())
  }
  x$plot.list[[i]]$labels$y = element_blank()
}

x$plot.list[[1]]$labels$y = "Final Week Frequency"

grid.arrange(
             x$plot.list[[1]]+ geom_point(),
             x$plot.list[[2]]+ geom_point(),
             x$plot.list[[3]], 
             x$plot.list[[4]], 
             widths=c(2,1,2,2))

pdf("../results/descriptive/graphs/EffectsPlot.pdf", width=8.5, height=3.5)
grid.arrange(
             x$plot.list[[1]]+ geom_point(),
             x$plot.list[[2]]+ geom_point(),
             x$plot.list[[3]], 
             x$plot.list[[4]], 
             widths=c(2,1,2,2))
dev.off()

```

\newpage

Check model assumptions.  The model is not good at predicting higher values.

```{r}
sjp.glmer(finalModel, 'ma')
```





