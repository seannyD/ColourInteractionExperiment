---
title: "Colour experiment"
output: 
    pdf_document:
        toc: true
---


\newpage

# Introduction

This analysis looks at the sign variants used in a colour naming game between signers of different sign languages meeting after 1 week of interaction and after 3 weeks of interaction.  The data was collected by Kang Suk Byun (Kang-Suk.Byun@mpi.nl).

The analysis tries to predict the relative frequency of each variant within a colour category in week 3, based on measures from week 1.

## Data

-  colour: Code of the target colour
-  colourName: English name of the target colour
-  sign: label for the variant produced
-  freq_week_1_total: Total number of occurances of the variant in the first week, across all colour contexts.
-  freq_week_4_total: Total number of occurances of the variant in the final week, across all colour contexts.
-  freq_week_1: Number of occurances of the variant used during the given target colour context in week 1.
-  freq_week_4: Number of occurances of the variant used during the given target colour context in the final week.
-  prop_week_1: Same as freq_week_1, but as a proportion of all variants used in the given colour context.
-  prop_week_4: Same as freq_week_4, but as a proportion of all variants used in the given colour context.
-  origin:  The origin language of the sign.  For many, identifying an origin is not possible, so is labelled "None"
-  iconic: Old variable
-  check: The number of times this variable was used in a checking turn.
-  indexical:  Is the variant non-indexical, indexical or indexical of the body?
-  inventedBy:  The name of the first signer to use this variant in the experiment.
-  TryMarked:  The number of times this sign was used in try-marking.
-  Teach:  The number of times this sign was explicitly taught.
-  averageLength_week_1:  Average time to produce the variant in milliseconds
-  averageTrialLength_week_1:  Average time for completing the trial for the given target colour.
-  BodyAnchor:  Is the variant body-anchored (redundant with 'indexical')

\newpage

## Poisson regression

This study uses a mixed effects regression model with poisson distributions.  Most standard regression analyses assume that the values they are trying to model come from a normal distribution, like this:

```{r echo=F}
set.seed(237)
hist(rnorm(1000, mean = 8, sd = 2), main='', xlab='Frequency', ylab='Count')
```

However, the main variable for this study is the frequency of sign variants, with a strong skew and many zero values:

```{r echo=F}
variants = read.csv('../data/processedData/variants_summary.csv', stringsAsFactors = F)
hist(variants$freq_week_4, main='', xlab='Frequency', ylab='Count')
```

Instead of using a normal distribution as the basis for the statistical model or transforming the data (which is difficult anyway because of the large number of zero counts), we can use a poisson distribution.  This also has the advantage of only predicting whole, non-negative numbers, which makes sense for this data because a variant can't be used half a time or a negative number of times.

# Load libraries
```{r warning=F, message=F}

library(ggplot2)
library(lme4)
library(party)
library(Rmisc)
library(dplyr)

```

```{r echo=F}

setwd("~/Documents/MPI/KangSukColours/ColourExperiment/analysis/")

getMEText = function(r,ef, wald=NULL, showWald=F){
  
  AIC = r[2,]$AIC
  loglikDiff = signif(diff(r$logLik),2)
  chi = round(r$Chisq[2],2)
  df = r$`Chi Df`[2]
  p = signif(r$`Pr(>Chisq)`[2],2)
  
  wald.text = ""
  
  if(!is.null(wald)){
    est = signif(wald[1],2)
    stder = signif(wald[2],2)
    t = signif(wald[3],2)
    wptext = ""
    wald.text =  paste("beta = ",est,",")
    if(showWald){
      if(!is.na(wald[4])){
      wptext = paste(", Wald p =",signif(wald[4],2))
      }
    wald.text = paste("beta = ",est,", std.err = ",stder, ", Wald t = ",t,wptext,';')
    }
  }
  
  begin = 'There was no significant'
  if(p <0.09){
    begin = "There was a marginal"
  }
  if(p < 0.05){
    begin = 'There was a significant'  
  }
  
  
  return(paste(begin,ef,"(",wald.text,"log likelihood difference =",
               loglikDiff,", df = ",df,", Chi Squared =", chi,", p = ",p,")."))
}

```

# Load data

```{r}
variants = read.csv('../data/processedData/variants_summary.csv', stringsAsFactors = F)
```

There is only 1 variant for `white'.  Therefore, we remove it from this statistical analysis.

```{r}
variants = variants[variants$colourName!='white',]
```

Transform some variables.

```{r}

# The range of values for 'Teach' is very small:
table(variants$Teach)
# So we'll turn it into a binary category: 
#  variants that were never taught and variants that were
variants$Teach = variants$Teach >0

# Similar for checking
variants$check.any = variants$check>0

# Transform total frequency
variants$freq_week_1_total.logcenter = 
  log(variants$freq_week_1_total + 1)
variants$freq_week_1_total.logcenter = 
  variants$freq_week_1_total.logcenter - mean(variants$freq_week_1_total.logcenter)

# cut TryMarking into two categories
variants$TryMarked.cat = cut(variants$TryMarked, 
                             c(-Inf,3,Inf), 
                             labels = c("Low",'High')) 

# transform length
variants$averageLength_week_1.logcenter = log(variants$averageLength_week_1)
variants$averageLength_week_1.logcenter = 
  variants$averageLength_week_1.logcenter -
    mean(variants$averageLength_week_1.logcenter)

listofsigns = variants[,c("colourName","sign")]
write.csv(listofsigns,"../results/descriptive/ListOfVariants.csv", fileEncoding = 'utf-8')

```



# LMER models

Each model predicts the frequency of a variant in week 4, with a random intercept by colourName.  The random intercept allows some colours to have higher variant frequencies than others.  This is useful because we know that signs for some colours are converged on quickly, making their frequencies within those colours potentially higher.  In other words, the use of a particular variant to refer to a given colour is not entierly independent of the use of another variant to refer to the same colour.

We begin with a null model and gradually add predictor variables, using model comparison to judge the significance of each variable.

```{r modelBits, cache=T}
# Null model
m0 = glmer(freq_week_4 ~ 
             1
           + (1 | colourName) , 
           data=variants, family=poisson)

# add indexicality
m1 = glmer(freq_week_4 ~ 
             1 + 
             indexical + 
            (1 | colourName) , 
           data=variants, family=poisson)

# add whether the variant is explicitly taught
m2 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
            (1 | colourName) , 
           data=variants, family=poisson)

m3 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
             TryMarked +
            (1 | colourName) , 
           data=variants, family=poisson)

m4 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
            (1 | colourName) , 
           data=variants, family=poisson)

m5 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
            (1 | colourName) , 
           data=variants, family=poisson)

m6 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
            (1 | colourName) , 
           data=variants, family=poisson)

m7 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
            (1 | colourName) , 
           data=variants, family=poisson)

m8 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
            (1 | colourName) , 
           data=variants, family=poisson)

m9 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
             Teach : check.any +
            (1 | colourName) , 
           data=variants, family=poisson)

m10 = glmer(freq_week_4 ~ 
             1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
             Teach : check.any +
             TryMarked : check.any +
            (1 | colourName) , 
           data=variants, family=poisson)

```

# Results

Model comparison test:

```{r}
anova(m0,m1,m2,m3,m4,m5, m6,m7,m8, m9, m10)
```

Choose a final model for the beta values (based on m9).

```{r finalModel, cache=T}
finalModel = glmer(freq_week_4 ~ 
            1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
             Teach : check.any +
            (1  | colourName), 
          data=variants, family=poisson)
```

Fixed effects:

```{r}
coef(summary(finalModel))[,1:3]
```


Random effects:

```{r}
dotplot(ranef(finalModel))
```

Check the predictions:

```{r}
plot(variants$freq_week_4, exp(predict(finalModel)),
     xlab="Actual frequency",
     ylab="Model prediction")
```

# Random slopes

For each of the predictors, we see if random slopes help improve the model.  Random slopes allow the strenght of the effect of a factor to be different for each colour concept.  There were many convergence issues with some of the models (hence chancing the optimiser and maximum iterations below), which indicates that the random slopes may not be suitable with this amount of data.  However, the tests below can serve as indicators about whether there is variation within colours.

```{r randomSlopes, cache=T}

rsControl = glmerControl(
            optimizer = "bobyqa",
            optCtrl = list(maxfun=500000))

m9R = glmer(freq_week_4 ~ 
            1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
             Teach : check.any +
           (1 | colourName) , 
          data=variants, family=poisson,
          control = rsControl)
          
m9R.indexical = glmer(freq_week_4 ~ 
            1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
             Teach : check.any +
           (1 + indexical| colourName), 
          data=variants, family=poisson,
          control = rsControl)

anova(m9R,m9R.indexical)

m9R.Teach = glmer(freq_week_4 ~ 
            1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
             Teach : check.any +
          (1 + Teach| colourName),
          data=variants, family=poisson,
          control=rsControl)
anova(m9R,m9R.Teach)

m9R.TryMark = glmer(freq_week_4 ~ 
          1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
             Teach : check.any +
          (1 + TryMarked| colourName), 
          data=variants, family=poisson,
          control = rsControl)
anova(m9R,m9R.TryMark)



m9R.Check = glmer(freq_week_4 ~ 
           1 +  
             indexical + 
             Teach +
             TryMarked +
             check.any +
             freq_week_1_total +
             averageLength_week_1.logcenter +
             inventedBy +
             Teach : TryMarked +
             Teach : check.any +
          (1 + check.any| colourName), 
          data=variants, family=poisson,
          control = rsControl)
anova(m9R,m9R.Check)
```

## Random slopes results

The only significant improvement in the model was from adding a random slope by indexicality.  We can plot the random slopes below:

```{r}
dotplot(ranef(m9R.indexical))
```

The effect of indexicality is stronger for black and red, and weaker for green and pink.

\newpage

# Summary

Here is a summary of the main results:

`r getMEText(anova(m0,m1), "main effect of indexicality",summary(finalModel)$coef['indexicalYes',])` (beta for body-indexical = 0.853). Indexical variants were more frequent in the final week.

`r getMEText(anova(m1,m2), "main effect of teaching",summary(finalModel)$coef['TeachTRUE',])`  Teaching increased the frequency of variants in the final week.

`r getMEText(anova(m2,m3), "main effect of try marking",summary(finalModel)$coef['TryMarked',])` Variants that were try marked more often were more frequent in the final week.

`r getMEText(anova(m3,m4), "main effect of checking",summary(finalModel)$coef['check.anyTRUE',])`  Variants used in a checking context were more frequent in the final week.

`r getMEText(anova(m4,m5), "main effect of frequency in week 1",summary(finalModel)$coef['freq_week_1_total',])`  On its own, more frequent variants in week 1 are also more frequent in the final week (r = `r cor(variants$freq_week_1_total, variants$freq_week_4)`).  However, when considering this variable with the other variables the relationship dissappears.  An explanation may be the following:  A poor variant may be repeated many times before it is understood, while a good variant only needs to be used once.  That is, frequent use in the first week may be an indication of communication problems.  The sequential measures (teaching, try marking, checking) and indexicality are better measures of whether a variant is problematic, so the predictive power of frequency is small in comparison.

`r getMEText(anova(m5,m6), "main effect of sign length",summary(finalModel)$coef['averageLength_week_1.logcenter',])`  

`r getMEText(anova(m6,m7), "main effect of first user (inventedBy)")`  

`r getMEText(anova(m7,m8), "interaction between try marking and teaching",summary(finalModel)$coef['TeachTRUE:TryMarked',])` The effect of teaching was bigger when the variant was also often try marked (see graphs below). 

`r getMEText(anova(m8,m9), "interaction between teaching and checking",summary(finalModel)$coef['TeachTRUE:check.anyTRUE',])`  (see graphs below).

We also found some evidence that the effect of indexicality is more important for black and red, and less important for green and pink.

\newpage

# Graphs


## Teaching and Try marking

Plot the interaction between teaching and try marking.

Overall, the model suggests that teaching a variant improves its chances of being selected.  However, this effect is mainly due to the interaction between teaching and try marking.  


```{r}
sumStats2 = summarySE(variants, measurevar="freq_week_4",
                      groupvars=c("TryMarked.cat","Teach"))

dodge <- position_dodge(width=0.5) 

main.plot <- ggplot(sumStats2,
	aes(x = TryMarked.cat, y = freq_week_4, colour=Teach)) +
  geom_point(position=dodge, size=4) + geom_line(aes(group=Teach),position=dodge) +
  geom_errorbar(aes(ymax=freq_week_4+se, ymin=freq_week_4-se), width=0.25,position=dodge) +
  xlab("Try Marked Frequency") +
  ylab("Frequency in week 3") +
  coord_cartesian(ylim=c(0,6)) + 
  scale_color_discrete(breaks=c(FALSE,TRUE),
                       labels=c("No","Yes"),
                       name="Teach") +
  theme(text=element_text(size=18))
main.plot
```

```{r echo=F}
pdf("../results/descriptive/graphs/Interaction_Teach_TryMark.pdf", height=5, width=6)
main.plot
dev.off()
```




## Teaching and checking

Plot the interaction between teaching and checking.

```{r}
sumStats2 = summarySE(variants, measurevar="freq_week_4",
                      groupvars=c("Teach","check.any"))

dodge <- position_dodge(width=-0.5) 

main.plot2 <- ggplot(sumStats2,
	aes(x = check.any, y = freq_week_4, colour=Teach)) +
  geom_point(position=dodge, size=4) + geom_line(aes(group=Teach),position=dodge) +
  geom_errorbar(aes(ymax=freq_week_4+se, ymin=freq_week_4-se), width=0.25,position=dodge) +
  xlab("Check") +
  ylab("Proportional frequency in week 3") +
  coord_cartesian(ylim=c(0,3)) + 
  scale_color_discrete(breaks=c(FALSE,TRUE),
                       labels=c("No","Yes"),
                       name="Teach") +
  theme(text=element_text(size=18))
main.plot2
```


```{r echo=F, message=F, comment=F, warning=F}
pdf("../results/descriptive/graphs/Interaction_Teach_Check.pdf", height=5, width=6)
main.plot2
dev.off()
```




